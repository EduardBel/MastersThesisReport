\newpage

\thispagestyle{plain}

{
    \selectlanguage{english}
    \paragraph{} % Hack to ensure that TOC link works
    \begin{abstract}
        In the interconnected world we live in, Artificial Intelligence (AI) and Machine Learning (ML) have revolutionized our interactions with technology. Among emerging paradigms, Federated Learning (FL) is a new approach to train ML models in a decentralized way. FL allows ML models to obtain responses from users' data without compromising their privacy, making it essential for applications such as predictive text keyboards, speech recognition systems, and even disease diagnostic models.

        However, the intrinsic decentralization of FL also exposes it to security vulnerabilities. This research is motivated by the need to understand and address these vulnerabilities as FL is increasingly integrated into real-world applications, including critical systems such as autonomous driving vehicles.

        The main objective of this study is to investigate the vulnerabilities faced by FL systems and identify strategies to effectively mitigate possible attacks. Specifically, we explore the feasibility of intelligent label flipping techniques compared to brute force methods when attacking FL systems. Our goal is to determine whether a strategic selection of samples for label flipping can produce more successful attacks than indiscriminate label flipping.
        
        The obtained results show that indiscriminate attacks perform best when no defences are applied, but their effectiveness highly drops when countermeasures are present. The results also prove that our attacks, while not as effective in principle, are more able to evade defences.
    \end{abstract}
}

\vspace{10pt}

{
    \selectlanguage{spanish}
    \paragraph{} % Hack to ensure that TOC link works
    \begin{abstract}
        En el mundo interconectado en el que vivimos, la Inteligencia Artificial (IA) y el Aprendizaje Automático (AA) han revolucionado nuestras interacciones con la tecnología. Entre los paradigmas emergentes, el Aprendizaje Federado (AF) es un nuevo enfoque para el entrenamiento de modelos de IA de forma descentralizada. El AF permite que los modelos de AA puedan obtener respuestas de los datos de los usuarios sin comprometer la privacidad de éstos, lo que lo hace esencial para aplicaciones como los teclados de texto predictivo, los sistemas de reconocimiento de voz, e incluso en modelos de diagnóstico de enfermedades. 
        
        Sin embargo, la descentralización intrínseca del AF también le expone a vulnerabilidades de seguridad. Esta investigación se ve motivada en la necesidad de comprender y abordar estas vulnerabilidades ya que el AF se integra cada vez más en aplicaciones del mundo real, incluidos sistemas críticos como los vehículos con conducción autónoma.
        
        El objetivo principal de este estudio es investigar las vulnerabilidades a las que se enfrentan los sistemas de AF e identificar estrategias para mitigar posibles ataques de forma efectiva. Específicamente, exploramos la viabilidad de técnicas inteligentes de manipulación de etiquetas en comparación con los métodos de fuerza bruta cuando se atacan sistemas de AF. Nuestro objetivo es determinar si una selección estratégica de muestras para la manipulación de etiquetas puede producir ataques más exitosos que la manipulación indiscriminada de etiquetas.
        
        Los resultados obtenidos muestran que los ataques indiscriminados funcionan mejor cuando no se aplican defensas, pero su efectividad disminuye considerablemente cuando están presentes las contramedidas. Los resultados también demuestran que nuestros ataques, aunque en principio no son tan efectivos, son más capaces de evadir las defensas.
    \end{abstract}
}

\vspace{10pt}
{
    \selectlanguage{catalan}
    \paragraph{} % Hack to ensure that TOC link works
    \begin{abstract}
        En el món interconnectat en el que vivim, la Intel·ligència Artificial (IA) i l'Aprenentatge Automàtic (AA) han revolucionat les nostres interaccions amb la tecnologia. Entre els paradigmes emergents, l'Aprenentatge Federat (AF) és un nou enfocament per a l'entrenament de models d'IA de forma descentralitzada. L'AF permet que els models d'AA puguin obtenir respostes de les dades dels usuaris sense comprometre la privacitat d'aquests, la qual cosa el fa essencial per a aplicacions com els teclats de text predictiu, els sistemes de reconeixement de veu, i fins i tot en models de diagnòstic de malalties.

        No obstant això, la descentralització intrínseca de l'AF també l'exposa a vulnerabilitats de seguretat. Aquesta investigació es veu motivada en la necessitat de comprendre i abordar aquestes vulnerabilitats ja que l'AF s'integra cada vegada més en aplicacions del món real, inclosos sistemes crítics com els vehicles amb conducció autònoma.

        L'objectiu principal d'aquest estudi és investigar les vulnerabilitats a les quals s'enfronten els sistemes d'AF i identificar estratègies per mitigar possibles atacs de forma efectiva. Específicament, explorem la viabilitat de tècniques intel·ligents de manipulació d'etiquetes en comparació amb els mètodes de força bruta quan s'ataquen sistemes d'AF. El nostre objectiu és determinar si una selecció estratègica de mostres per a la manipulació d'etiquetes pot produir atacs més reeixits que la manipulació indiscriminada d'etiquetes.

        Els resultats obtinguts mostren que els atacs indiscriminats funcionen millor quan no s'apliquen defenses, però la seva efectivitat disminueix considerablement quan estan presents les contramesures. Els resultats també demostren que els nostres atacs, encara que en principi no són tan efectius, són més capaços d'evadir les defenses.
    \end{abstract}
}

\newpage
